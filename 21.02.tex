\defn[Линейная независимость] $v_1\dots v_n$~---~линейно независимы, если
$\lambda_1v_1 + \dots + \lambda_nv_n = 0 \Rightarrow \lambda_i=0\;\forall i $.
\subsection{Базис}
\defn[Стандартный базис] Для пространства $K^n$ следующий набор назовём стандартным
базисом: $$
\begin{pmatrix}
1\\ 0\\ \vdots \\0
\end{pmatrix},
\begin{pmatrix}
0\\ 1\\ \vdots \\0
\end{pmatrix}
\dots
\begin{pmatrix}
0\\ 0\\ \vdots \\1
\end{pmatrix}$$
Очевидно, что этот набор линейно независим.
Точно так же работает для матриц, один элемент главной диагонали которых единица.


\fact Линейная зависимость в случае двух векторов $\Leftrightarrow$ вектора пропорциональны.
\fact Есть у нас есть набор линейно независимых векторов $v_1,\dots v_n$, то новый набор век
$v_1, \dots v_i, v_j + \lambda v_i, \dots v_n, i\not=j$ тоже линейно независим $\forall \lambda$.

Док-во:
Обозначим новый набор векторов как $v'_i$.
Рассмотрим $\sum_{k = 1}^{n}\mu_k v'_k = 0$, надо понять существуют ли такие нетривиальные $\mu_k$?

Раскрыв скобки, получим:
$(\sum_{k=1}^{n}\mu_kv_k) + \mu_j\lambda v_i = 0 \Rightarrow \mu_k=0\forall k\not=i$ и $\mu_i + \mu_j \lambda = 0$
по линейной независимости векторов(а значит коэффициенты при всех векторах точно 0).
Значит $\mu_i=0$, так как $\mu_j\lambda= 0$.

Доказав факт выше мы получили что-то похожее на элементарное преобразование системы первого типа.
Теперь давайте поймём что-то про размерность

\thm[О линейной зависимости линейной комбинации] Для произвольного набора векторов
$v_1,\dots v_n\in V$, строим набор векторов такой, что каждый из
$u_1,\dots u_m$~---~линейная комбинация $v$. 
Тогда, если $m > n$, то набор векторов $u$ линейно зависим.

Доказательство:
Будем доказывать индукцией по $n$, считая что $m$ у нас фиксировано.

База индукции:\\$n = 1, m > 2$, все $u_i = \lambda_i\cdot v_1$, тогда по факту выше $u$ линейно зависимы.

Индукционный переход: $n - 1\rightarrow n$:\\
Определим $\lambda_{i,j}$ следующим образом: $u_i = \sum_{j=0}^{n} \lambda_{i,j} v_j$.
Найдём вектор $u_k: \lambda_{k,n}\not=0$, если такого нет, тогда оказывается, что $v_n$ не
участвует в разложении ни одного $u_i$, а значит можем воспользоваться шагом индукции.

Перейдём к доказательству случая, где $u_k$ существует.
Посмотрим на новый набор векторов $u' = \left\{u_i - \frac{\lambda_{i,n}}{\lambda_{k,n}}u_k \mid i\not=k\right\}$.
Тогда каждый $u'_i$ выражается через $v_1,\dots,v_{n-1}$.
То есть у нас есть $m-1$ вектор, каждый из которых выражается
через $n-1$ вектор. А это значит, что данный набор $v'_1,\dots, v'_{m-1}$ линейно зависим по предположению индукции.

Расписав по определению, получим $\sum_{i=0}^{m-1}\mu_i u'_i = 0$, где не все $\mu_i=0$.
Распишем то же самое, но через $u_i$: $\sum_{i=0}^{m-1}\mu_iu_i + (\sum\dots)u_m=0$. Получается, что в этой
линейной комбинации тоже не все коэффициенты равны нулю, а значит мы нашли нетривиальную
линейную комбинацию. (Конец доказательства)
\bigskip

Для того, чтобы двигаться дальше дадим несколько определений.
\defn[Подпространство] Подпространством $V$ для набора векторов $v_1, \dots, v_n\in V$ называется
$$\{\lambda_1v_1 + \dots \lambda_nv_n \mid \lambda_i\in K\}$$
Причём, по теореме выше, это наименьшее подпространство содержащее $v_1,\dots,v_n$.
Далее обозначается как $<v_1,\dots, v_n>$.
\defn[Порождающая система] Если $<v_1,\dots v_n> = V$, то набор векторов называется
порождающей системой.
\defn[Базис] $v_1, \dots, v_n\in V$~--- базис, если:
\begin{enumerate}
    \item $v_1,\dots,v_n$ линейно независимы
    \item $v_1,\dots, v_n$~--- порождающая $V$
\end{enumerate}

\utvr
$v_1,\dots v_n \in V$ является базисом $\Leftrightarrow \forall v\in V\; \exists !\;
\lambda_1,\dots,\lambda_n:\; v = \sum_{i=1}^{n}\lambda_iv_i$.

Доказательство:\\
$\Leftarrow: $
\begin{enumerate}
    \item Пусть набор $v$ линейно зависим, тогда: $\exists \mu : \sum_{i=1}^{n}\mu_iv_i=0, \exists \mu_j\not=0$.
        Тогда расписав любой вектор, воспользовавшись условием, получим 
        $v = \sum_{i=1}^{n}\lambda_iv_i = \sum_{i=1}^{n}(\lambda_i+\mu_i)v_i$. То есть мы нашли
        второе разложение $v$ как линейную комбинацию $v_i$, что противоречит с единственностью $\lambda$.
        Значит $v$ линейно независим.
    \item $v_1,\dots, v_n$~--- порождающая $V$ просто так как любой вектор из $V$ выражается
        линейной комбинацией векторов из $v$.
\end{enumerate}
$\Rightarrow:$

$\exists \lambda_i \sum_{i=1}^{n} \lambda_iv_i = V$
Пусть есть две линейные комбинации, дающие $v$.
$\sum_{i=1}^{n} \lambda_iv_i = \sum_{i=1}^{n} \mu_iv_i = v$. Можем вычесть одну из другой, тогда
$\sum_{i=1}^{n}(\lambda_i - \mu_i)v_i = 0\Rightarrow \lambda_i-\mu_i=0\;\forall i
\Rightarrow \lambda_i = \mu_i\;\forall i$.
(Конец доказательства)
\bigskip

\example[Бесконечный базис] $1, x, x^2, \dots, x^n, \dots$~---~базис $K[x]$. 
Проблема бесконечного базиса в том, что многие факты доказываются сильно сложнее.
Поэтому полноценно работать с пространствами, которые имеют бесконечный базис, в рамках этого
курса мы не будем, но иногда будем приводить примеры таковых.

\thm $u_1,\dots,u_m\in V$~--- порождающий набор в $V$. $v_1,\dots,v_n\in V$~---
линейно независимый. Тогда $v_1,\dots, v_n$ можно дополнить до базиса добавив
какие-то вектора из $u_1\dots, u_m$.

Доказательство:\\
Идея банальна: добавляем по одному и в какой-то момент мы достигнем того, что набор
линейно независимым, но ни один вектор из $u$ мы не можем добавить не сделав набор
линейно зависимым.

Посмотрим на количество векторов из $u_1,\dots, u_m$, которые не
лежат в линейной комбинации в пространстве, порождённом $<v_1,\dots, v_n>$.
$v_1,\dots,v_n, u_1,\dots, u_k$ набор векторов в момент остановки. Хотим понять, что
мы получили базис.
Заметим, что в $<v_1,\dots,v_n,u_1,\dots,u_k>$ нельзя добавить ни одно $u_i\; i > k$, а значит
любое $u_i$ выражается через вектора из нашего множества(очевидно). Тогда мы получили
следующую цепочку:
$$V\supseteq <v_1,\dots,v_n, u_1,\dots,u_k> \supseteq <u_1,\dots,u_m>=V$$
(Конец доказательства)
\bigskip

\cor $v_1,\dots,v_n$~--- пуст $\Rightarrow$ в любом векторном пространстве есть базис.
\thm $V = <u_1,\dots,u_m> \Rightarrow$ размер любых двух базисов $V$ одинаков и конечен.\\
Доказательство:
$e_1,\dots,e_n$, $f_1,\dots,f_\alpha$~--- базисы. Знаем, что все $f_j$
выражаются через $e_i$ и все $e_i$ выражаются через $f_j$.
Допустим $\alpha > n$, тогда $f_1,\dots,f_\alpha$ линейно зависимы(по \textbf{теореме 1}), а значит $f$ не базис.
Для случая $\alpha < n$ всё аналогично.
(Конец доказательства)
\bigskip

\defn[Размерность пространства] $V$~--- век. пространство $dim V =$ количество 
векторов в базисе $V$.
\defn $V$~--- конечномерное, если $V = <u_1,\dots, u_m>$.
\rem Если $V$~--- конечномерное $U \leq V$, более того $dim U \leq dim V$, причём $dim U = dim V \Leftrightarrow U=V$.\\
Доказательство:
Возьмём $u_1,\dots,u_k\in U$, $K\leq dim V$. TODO()
\subsection{Алгебраические и трансцендентные числа}
\defn $\alpha\in\C$, $\alpha$~--- алгебраическое, если $\exists p(x)\not=0\in\Q[x] p(\alpha)=0$.
Иначе $\alpha$~--- трансцендентное.

Если $\alpha$~--- алгебраическое, $f(\alpha) = a_0 + a_1\alpha + \dots + a_n\alpha^n$
Вопрос: $f(\alpha)$~--- алгебраическое или нет?
Ответ:
$\alpha$~--- алгебраическое $\Rightarrow f(a)$~--- алгебраическое.  \subsection{Связь с теорией множеств}
\defn $U_1, U_2\leq V \Rightarrow U_1\cap U_2 \leq V$ и $U_1+U_2 =
\{u_1+u_2\mid u_1\in U_1; u_2\in U_2\}\in V$
\thm[Формула Грассмана] $V$~--- конечномерно. $U_1, U_2\leq V$. 
$dim U_1 + dim U_2 = dim(U_1+U_2) + dim(U_1\cap U_2)$
\rem Для трёх подпространств и более она \textbf{не работает} по аналогии с формулой включений исключений.
